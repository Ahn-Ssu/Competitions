{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "# from data_loader import CustomDataset\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_img_list = glob.glob('../aug_data/train/*/*')\n",
    "df = pd.DataFrame(columns=['img_path', 'label'])\n",
    "df['img_path'] = all_img_list\n",
    "df['label'] = df['img_path'].apply(lambda x : str(x).split('/')[-2])\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5,\n",
    "            shuffle=True,\n",
    "            random_state=41)\n",
    "\n",
    "all_splits = [k for k in kf.split(df, df['label'])]\n",
    "train_idx, val_idx = all_splits[0]\n",
    "train_idx, val_idx = train_idx.tolist(), val_idx.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['class 0', 'class 1', 'class 2', 'class 3']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       1.00      1.00      1.00         2\n",
      "     class 1       0.00      0.00      0.00         2\n",
      "     class 2       0.00      0.00      0.00         2\n",
      "     class 3       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.29         7\n",
      "   macro avg       0.25      0.25      0.25         7\n",
      "weighted avg       0.29      0.29      0.29         7\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/paper/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/envs/paper/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/envs/paper/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_true = [0, 1, 2, 0, 1, 2, 3]\n",
    "y_pred = [0, 2, 1, 0, 2, 1, 1]\n",
    "\n",
    "target_names = ['class 0', 'class 1', 'class 2', 'class 3']\n",
    "# target_names = [f'cls {idx}' for idx in range(19)]\n",
    "print(target_names)\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['              precision    recall  f1-score   support', '', '      class0       1.00      0.67      0.80         3', '      class1       0.00      0.00      0.00         2', '      class2       0.00      0.00      0.00         2', '', '    accuracy                           0.29         7', '   macro avg       0.33      0.22      0.27         7', 'weighted avg       0.43      0.29      0.34         7', '']\n",
      "10\n",
      "\n",
      "line content:               precision    recall  f1-score   support\n",
      "line content: \n",
      "line content:       class0       1.00      0.67      0.80         3\n",
      "line content:       class1       0.00      0.00      0.00         2\n",
      "line content:       class2       0.00      0.00      0.00         2\n",
      "line content: \n",
      "line content:     accuracy                           0.29         7\n",
      "line content:    macro avg       0.33      0.22      0.27         7\n",
      "line content: weighted avg       0.43      0.29      0.34         7\n",
      "line content: \n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_true = [0, 1, 2, 0, 1, 2, 0]\n",
    "y_pred = [0, 2, 1, 0, 2, 1, 1]\n",
    "\n",
    "target_names = ['class0', 'class1', 'class2']\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=target_names)\n",
    "report_lines = report.split('\\n')\n",
    "\n",
    "# 클래스별 지표 추출\n",
    "metrics = {}\n",
    "print(report_lines)\n",
    "print(len(report_lines))\n",
    "print()\n",
    "for line in report_lines:\n",
    "    print(f'line content: {line}')\n",
    "    if not line and len(line) > 2:\n",
    "        class_name, *class_metrics, support = line.split()\n",
    "        print(f'cls name: {class_name}')\n",
    "        print(f'class_metrics: {class_metrics}')\n",
    "        print(f'support {support}')\n",
    "    # metrics[class_name] = {\n",
    "    #     'precision': float(class_metrics[0]),\n",
    "    #     'recall': float(class_metrics[1]),\n",
    "    #     'f1-score': float(class_metrics[2]),\n",
    "    #     'support': int(support),\n",
    "    # }\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all splits length: [5]\n",
      "all splits[0][0] shape: [(2896,)]\n",
      "all splits[0][1] shape: [(724,)]\n"
     ]
    }
   ],
   "source": [
    "print(f'all splits length: [{len(all_splits)}]')\n",
    "print(f'all splits[0][0] shape: [{all_splits[0][0].shape}]') # 80%\n",
    "print(f'all splits[0][1] shape: [{all_splits[0][1].shape}]') # 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape from train_idx : [(2896, 2)]\n",
      "df shape from val_idx : [(724, 2)]\n"
     ]
    }
   ],
   "source": [
    "print(f'df shape from train_idx : [{df.iloc[train_idx].shape}]')\n",
    "print(f'df shape from val_idx : [{df.iloc[val_idx].shape}]')\n",
    "\n",
    "train = df.iloc[train_idx]\n",
    "val = df.iloc[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../aug_data/train/들뜸/24.png</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../aug_data/train/들뜸/34.png</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../aug_data/train/들뜸/25.png</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../aug_data/train/들뜸/5.png</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../aug_data/train/들뜸/8.png</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3615</th>\n",
       "      <td>../aug_data/train/틈새과다/0.png</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3616</th>\n",
       "      <td>../aug_data/train/틈새과다/3.png</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3617</th>\n",
       "      <td>../aug_data/train/틈새과다/4.png</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3618</th>\n",
       "      <td>../aug_data/train/틈새과다/1.png</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3619</th>\n",
       "      <td>../aug_data/train/틈새과다/2.png</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3620 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          img_path  label\n",
       "0      ../aug_data/train/들뜸/24.png      5\n",
       "1      ../aug_data/train/들뜸/34.png      5\n",
       "2      ../aug_data/train/들뜸/25.png      5\n",
       "3       ../aug_data/train/들뜸/5.png      5\n",
       "4       ../aug_data/train/들뜸/8.png      5\n",
       "...                            ...    ...\n",
       "3615  ../aug_data/train/틈새과다/0.png     16\n",
       "3616  ../aug_data/train/틈새과다/3.png     16\n",
       "3617  ../aug_data/train/틈새과다/4.png     16\n",
       "3618  ../aug_data/train/틈새과다/1.png     16\n",
       "3619  ../aug_data/train/틈새과다/2.png     16\n",
       "\n",
       "[3620 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "df['label'] = le.fit_transform(df['label'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  12.,  317.,  187.,  219.,   21.,   57.,  107.,  134.,   28.,   60.,\n",
       "         587.,  149.,   54.,   27.,   34.,  192.,    5.,   55., 1375.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.Tensor(df.label.value_counts().to_frame().sort_index().values).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LADELoss()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LADELoss(19, df.label.value_counts().to_frame().sort_index().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import functools\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "# from utils import *\n",
    "\n",
    "\n",
    "class LADELoss(nn.Module):\n",
    "    def __init__(self, num_classes=10, prior=None, remine_lambda=0.1):\n",
    "        super().__init__()\n",
    "        if prior is not None:\n",
    "            self.img_num_per_cls = torch.Tensor(prior).squeeze().cuda()\n",
    "            self.prior = self.img_num_per_cls / self.img_num_per_cls.sum()\n",
    "        else:\n",
    "            self.prior = None\n",
    "\n",
    "        self.balanced_prior = torch.tensor(1. / num_classes).float().cuda()\n",
    "        self.remine_lambda = remine_lambda\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.cls_weight = (self.img_num_per_cls.float() / torch.sum(self.img_num_per_cls.float())).cuda()\n",
    "\n",
    "    def mine_lower_bound(self, x_p, x_q, num_samples_per_cls):\n",
    "        N = x_p.size(-1)\n",
    "        first_term = torch.sum(x_p, -1) / (num_samples_per_cls + 1e-8)\n",
    "        second_term = torch.logsumexp(x_q, -1) - np.log(N)\n",
    "\n",
    "        return first_term - second_term, first_term, second_term\n",
    "\n",
    "    def remine_lower_bound(self, x_p, x_q, num_samples_per_cls):\n",
    "        loss, first_term, second_term = self.mine_lower_bound(x_p, x_q, num_samples_per_cls)\n",
    "        reg = (second_term ** 2) * self.remine_lambda\n",
    "        return loss - reg, first_term, second_term\n",
    "\n",
    "    def forward(self, y_pred, target, q_pred=None):\n",
    "        \"\"\"\n",
    "        y_pred: N x C\n",
    "        target: N\n",
    "        \"\"\"\n",
    "        per_cls_pred_spread = y_pred.T * (target == torch.arange(0, self.num_classes).view(-1, 1).type_as(target))  # C x N\n",
    "        pred_spread = (y_pred - torch.log(self.prior + 1e-9) + torch.log(self.balanced_prior + 1e-9)).T  # C x N\n",
    "\n",
    "        num_samples_per_cls = torch.sum(target == torch.arange(0, self.num_classes).view(-1, 1).type_as(target), -1).float()  # C\n",
    "        estim_loss, first_term, second_term = self.remine_lower_bound(per_cls_pred_spread, pred_spread, num_samples_per_cls)\n",
    "\n",
    "        loss = -torch.sum(estim_loss * self.cls_weight)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18    1100\n",
       "10     469\n",
       "1      253\n",
       "3      175\n",
       "15     153\n",
       "2      150\n",
       "11     119\n",
       "7      108\n",
       "6       86\n",
       "9       48\n",
       "5       46\n",
       "17      44\n",
       "12      43\n",
       "14      28\n",
       "13      22\n",
       "8       22\n",
       "4       17\n",
       "0        9\n",
       "16       4\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18    275\n",
       "10    118\n",
       "1      64\n",
       "3      44\n",
       "15     39\n",
       "2      37\n",
       "11     30\n",
       "7      26\n",
       "6      21\n",
       "9      12\n",
       "5      11\n",
       "12     11\n",
       "17     11\n",
       "8       6\n",
       "14      6\n",
       "13      5\n",
       "4       4\n",
       "0       3\n",
       "16      1\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train['img_path'].values, train['label'].values, train_transform_4_origin)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
