args: !!python/object/new:easydict.EasyDict
  dictitems:
    FF_hidden_dim: 2048
    atomic_feature_list: &id001
    - SH
    - DMPNN
    - BPS
    batch_size: 16
    epoch: 100
    gnn_hidden_dims: &id002
    - 64
    - 128
    - 256
    - 512
    init_lr: 5.0e-05
    lr_dec_rate: 0.01
    mol_feature_list: &id003
    - new
    - rdkit
    num_atom_f: 167
    num_fp_f: 300
    num_mol_f: 219
    out_dim: 2
    projection_dim: 1479
    seed: 41
    server: mk3
    weight_decay: 0.1
    z_model_arch: "Molp(\n  (gnn_encoder): GIN(\n    (conv1): GCNConv(167, 64)\n \
      \   (conv2): GCNConv(64, 128)\n    (conv3): GCNConv(128, 256)\n    (conv4):\
      \ GCNConv(256, 512)\n    (norm1): InstanceNorm(64)\n    (norm2): InstanceNorm(128)\n\
      \    (norm3): InstanceNorm(256)\n    (norm4): InstanceNorm(512)\n    (act):\
      \ SELU()\n  )\n  (fc1): Linear(in_features=1479, out_features=2048, bias=True)\n\
      \  (fc2): Linear(in_features=2048, out_features=2048, bias=True)\n  (fc3): Linear(in_features=2048,\
      \ out_features=2048, bias=True)\n  (fc_out): Linear(in_features=2048, out_features=2,\
      \ bias=True)\n  (ln1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n\
      \  (ln2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n  (ln3): LayerNorm((2048,),\
      \ eps=1e-05, elementwise_affine=True)\n  (activation): SELU()\n  (dropout):\
      \ Dropout(p=0.7, inplace=False)\n)"
  state:
    FF_hidden_dim: 2048
    atomic_feature_list: *id001
    batch_size: 16
    epoch: 100
    gnn_hidden_dims: *id002
    init_lr: 5.0e-05
    lr_dec_rate: 0.01
    mol_feature_list: *id003
    num_atom_f: 167
    num_fp_f: 300
    num_mol_f: 219
    out_dim: 2
    projection_dim: 1479
    seed: 41
    server: mk3
    weight_decay: 0.1
    z_model_arch: "Molp(\n  (gnn_encoder): GIN(\n    (conv1): GCNConv(167, 64)\n \
      \   (conv2): GCNConv(64, 128)\n    (conv3): GCNConv(128, 256)\n    (conv4):\
      \ GCNConv(256, 512)\n    (norm1): InstanceNorm(64)\n    (norm2): InstanceNorm(128)\n\
      \    (norm3): InstanceNorm(256)\n    (norm4): InstanceNorm(512)\n    (act):\
      \ SELU()\n  )\n  (fc1): Linear(in_features=1479, out_features=2048, bias=True)\n\
      \  (fc2): Linear(in_features=2048, out_features=2048, bias=True)\n  (fc3): Linear(in_features=2048,\
      \ out_features=2048, bias=True)\n  (fc_out): Linear(in_features=2048, out_features=2,\
      \ bias=True)\n  (ln1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n\
      \  (ln2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n  (ln3): LayerNorm((2048,),\
      \ eps=1e-05, elementwise_affine=True)\n  (activation): SELU()\n  (dropout):\
      \ Dropout(p=0.7, inplace=False)\n)"
